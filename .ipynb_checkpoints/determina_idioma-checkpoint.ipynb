{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords #Listas de stopword\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(corpus):\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    sents =  [word_tokenize(s) for s in sent_tokenize(open(corpus,'r', encoding='utf8').read())]\n",
    "    #Separamos por palabras#\n",
    "    #limpieza_corpus = [w for w in sents if w.isalpha()] \n",
    "    stopwords_list = stopwords.words('spanish')\n",
    "    #print(limpieza_corpus)\n",
    "    #Expresión regular para limpieza de signos\n",
    "    exp_reg_signal = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    clean_signal = [exp_reg_signal.sub('', str(w)) for w in sents]\n",
    "    print(clean_signal)\n",
    "    ##Limpieza de espacios en blanco al final e inicio de la cadena\n",
    "    exp_reg_space = re.compile('^\\s+|\\s+$')\n",
    "    clean_space = [exp_reg_space.sub('', w) for w in clean_signal]\n",
    "    #Limpieza de espacios duplicados en las cadenas\n",
    "    exp_reg_spaces = re.compile(r'\\s{2,}?')\n",
    "    clean_spaces = [exp_reg_spaces.sub('', w) for w in clean_space]\n",
    "    clean_corpus = clean_spaces\n",
    "    return clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_esp = ['el perro come un hueso', 'un muchacho jugaba', 'el muchacho saltaba la cuerda',\n",
    "          'un gato come croquetas']\n",
    "corpus_en = ['The dog eats a bone', 'a boy played', 'the boy was jumping rope', 'a cat eats croquettes']\n",
    "corpus_ale = ['Der Hund frisst einen Knochen', 'ein Junge spielte', 'der Junge war Seilspringen', 'eine katze isst kroketten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = []\n",
    "for i in corpus:\n",
    "    pal = i.split(' ')\n",
    "    for j in pal:\n",
    "        for k in range(0, len(j),1):\n",
    "            #bigram.append(j[k])\n",
    "            if(len(j[k:k+1])==0):\n",
    "                #print(j[k:k+2]+\"_\")\n",
    "                letras.append(j[k:k+1]+\"_\")\n",
    "            else:\n",
    "                letras.append(j[k:k+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = []\n",
    "for i in corpus:\n",
    "    pal = i.split(' ')\n",
    "    for j in pal:\n",
    "        for k in range(0, len(j),2):\n",
    "            #bigram.append(j[k])\n",
    "            if(len(j[k:k+2])==1):\n",
    "                #print(j[k:k+2]+\"_\")\n",
    "                bigram.append(j[k:k+2]+\"_\")\n",
    "            else:\n",
    "                bigram.append(j[k:k+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_ngram(ngram, corpus, n):\n",
    "    for i in corpus:\n",
    "        pal = re.split('[a-z][A-Z]', i)\n",
    "        for j in pal:\n",
    "            for k in range(0, len(j),n):\n",
    "                ngram.append(j[k:k+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-d5ae3347cde7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbigrama_ale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcorpus_ngram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigrama\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimpieza\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpus/la_biblioteca_de_babel_esp.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#corpus_ngram(bigram, corpus_en,n_gram)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#corpus_ngram(bigrama_ale, corpus_ale,n_gram)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-ca8b696a7d4b>\u001b[0m in \u001b[0;36mlimpieza\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(limpieza_corpus)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#Expresión regular para limpieza de signos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mexp_reg_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[%s]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mclean_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexp_reg_signal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_signal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "bigrama = []\n",
    "bigram = []\n",
    "bigrama_ale = []\n",
    "n_gram = 2\n",
    "corpus_ngram(bigrama, limpieza('corpus/la_biblioteca_de_babel_esp.txt'),n_gram)\n",
    "#corpus_ngram(bigram, corpus_en,n_gram)\n",
    "#corpus_ngram(bigrama_ale, corpus_ale,n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08974358974358974"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def jaccard(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)+(list3)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "#find Jaccard Similarity between the two sets \n",
    "jaccard(bigrama, bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_letras = Counter(letras)\n",
    "frec_bigram = Counter(bigram)\n",
    "frec_trigram = Counter(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'el ': 2,\n",
       "         'per': 1,\n",
       "         'ro ': 1,\n",
       "         'com': 1,\n",
       "         'e u': 1,\n",
       "         'n h': 1,\n",
       "         'ues': 1,\n",
       "         'o': 1,\n",
       "         'un ': 2,\n",
       "         'muc': 2,\n",
       "         'hac': 2,\n",
       "         'ho ': 2,\n",
       "         'jug': 1,\n",
       "         'aba': 1,\n",
       "         'sal': 1,\n",
       "         'tab': 1,\n",
       "         'a l': 1,\n",
       "         'a c': 1,\n",
       "         'uer': 1,\n",
       "         'da': 1,\n",
       "         'gat': 1,\n",
       "         'o c': 1,\n",
       "         'ome': 1,\n",
       "         ' cr': 1,\n",
       "         'oqu': 1,\n",
       "         'eta': 1,\n",
       "         's': 1})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frec_trigram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
