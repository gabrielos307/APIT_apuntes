{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre: \n",
    "Herrera Gandarela Gabriel Alejandro\n",
    "#### Materia: \n",
    "Análisis y Procesamiento Inteligente de Textos\n",
    "#### Ejercicio:\n",
    "Creación de un sistema de clasificación de lengua basado en caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(corpus):\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    sents =  [word_tokenize(s) for s in sent_tokenize(open(corpus,'r', encoding='utf8').read())]\n",
    "    #Separamos por palabras#\n",
    "    #limpieza_corpus = [w for w in sents if w.isalpha()] \n",
    "    stopwords_list = stopwords.words('spanish')\n",
    "    #print(limpieza_corpus)\n",
    "    #Expresión regular para limpieza de signos\n",
    "    exp_reg_signal = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    clean_signal = [exp_reg_signal.sub('', str(w)) for w in sents]\n",
    "    #print(clean_signal)\n",
    "    ##Limpieza de espacios en blanco al final e inicio de la cadena\n",
    "    exp_reg_space = re.compile('^\\s+|\\s+$')\n",
    "    clean_space = [exp_reg_space.sub('', w) for w in clean_signal]\n",
    "    #Limpieza de espacios duplicados en las cadenas\n",
    "    exp_reg_spaces = re.compile(r'\\s{2,}?')\n",
    "    clean_spaces = [exp_reg_spaces.sub('', w) for w in clean_space]\n",
    "    clean_corpus = clean_spaces\n",
    "    return clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = []\n",
    "for i in corpus:\n",
    "    pal = i.split(' ')\n",
    "    for j in pal:\n",
    "        for k in range(0, len(j),1):\n",
    "            #bigram.append(j[k])\n",
    "            if(len(j[k:k+1])==0):\n",
    "                #print(j[k:k+2]+\"_\")\n",
    "                letras.append(j[k:k+1]+\"_\")\n",
    "            else:\n",
    "                letras.append(j[k:k+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = []\n",
    "for i in corpus:\n",
    "    pal = i.split(' ')\n",
    "    for j in pal:\n",
    "        for k in range(0, len(j),2):\n",
    "            #bigram.append(j[k])\n",
    "            if(len(j[k:k+2])==1):\n",
    "                #print(j[k:k+2]+\"_\")\n",
    "                bigram.append(j[k:k+2]+\"_\")\n",
    "            else:\n",
    "                bigram.append(j[k:k+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función que convierte a ngramas el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_ngram(ngram, corpus, n):\n",
    "    for i in corpus:\n",
    "        pal = re.split('[a-z][A-Z]', i)\n",
    "        for j in pal:\n",
    "            for k in range(0, len(j),n):\n",
    "                ngram.append(j[k:k+n])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0697145373156234"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función que determina qué número es mayor\n",
    "La aplicaremos para determinar cual es la distancia mayor de acuerdo con la comparación entre cada corpus de entrenamiento del idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_mayor(num1, num2, num3):\n",
    "    if(num1>num2):\n",
    "        if(num1>num3):\n",
    "            print(\"EL idioma introducido es español\")\n",
    "    elif(num3>num2):\n",
    "        print(\"EL idioma introducido es aleman\")\n",
    "    else:\n",
    "        if(num2>num3):\n",
    "            print(\"EL idioma introducido es inglés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valida_idioma(corpus_prueba):\n",
    "    n_gram = int(input(\"Ngrama que quieres calcular\")) \n",
    "    grama_entrena_es = [] #grama de entrenamiento para español \n",
    "    grama_entrena_en = [] ##grama de entrenamiento para ingles\n",
    "    grama_entrena_ale = [] ##grama de entrenamiento para aleman\n",
    "    grama_prueba = [] #Grama de prueba\n",
    "    #para cada corpus, hacemos la limpieza y lo almacenamos en una lista\n",
    "    corpus_ngram(grama_entrena_es, limpieza('corpus/la_biblioteca_de_babel_esp.txt'),n_gram)\n",
    "    corpus_ngram(grama_entrena_en, limpieza('corpus/la_biblioteca_de_babel_en.txt'),n_gram)\n",
    "    corpus_ngram(grama_entrena_ale, limpieza('corpus/la_biblioteca_de_babel_ale.txt'),n_gram)\n",
    "    #creamos un ngrama para el corpus de prueba\n",
    "    corpus_ngram(grama_prueba, corpus_prueba,n_gram)\n",
    "    #calculamos la distancia entre cada idioma de acuerdo con el algoritmo de jacard\n",
    "    #recibe dos listas, una será el grama de entremiento y otro de prueba\n",
    "    #Calculamos las distancias para cada idioma\n",
    "    num_esp= jaccard(grama_entrena_es,grama_prueba)*1000\n",
    "    num_en= jaccard(grama_entrena_en,grama_prueba)*1000\n",
    "    num_ale= jaccard(grama_entrena_ale,grama_prueba)*1000\n",
    "    #ejecutamos la función que calcula la distancia mayor\n",
    "    #entre mayor sea la distancia, significa que ese será el idioma seleccionado\n",
    "    num_mayor(num_esp, num_en, num_ale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_esp = ['el perro come un hueso', 'un muchacho jugaba', 'el muchacho saltaba la cuerda',\n",
    "          'un gato come croquetas']\n",
    "corpus_en = ['The dog eats a bone', 'a boy played', 'the boy was jumping rope', 'a cat eats croquettes']\n",
    "corpus_ale = ['Der Hund frisst einen Knochen', 'ein Junge spielte', 'der Junge war Seilspringen', 'eine katze isst kroketten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-2b021d7b227d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     corpus_prueba.append(oracion)  \"\"\"  \n\u001b[0;32m      5\u001b[0m \u001b[1;31m#prueba de corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvalida_idioma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_esp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-216-b226ad28e666>\u001b[0m in \u001b[0;36mvalida_idioma\u001b[1;34m(corpus_prueba)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvalida_idioma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_prueba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mn_gram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ngrama que quieres calcular\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mgrama_entrena_es\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgrama_entrena_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrama_entrena_ale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             )\n\u001b[1;32m--> 857\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\"\"\"corpus_prueba = []\n",
    "for num in range(0,3):\n",
    "    oracion = input(\"Escribe la oracion \"+str(num+1))\n",
    "    corpus_prueba.append(oracion)  \"\"\"  \n",
    "#prueba de corpus_\n",
    "valida_idioma(corpus_esp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_letras = Counter(letras)\n",
    "frec_bigram = Counter(bigrama)\n",
    "frec_trigram = Counter(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que calcula la distancia entre dos listas \n",
    "https://www.statology.org/jaccard-similarity-python/\n",
    "\n",
    "\n",
    "Apuntes del Profesor Víctor Mijangos de la materia Procesamiento Inteligente de Textos\n",
    "https://github.com/VMijangos/Curso-Procesamiento-de-Lenguaje-Natural/tree/master/Notebooks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
